{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2288790/2288790 [00:01<00:00, 1608394.49it/s]\n"
     ]
    }
   ],
   "source": [
    "with open('../data/train_data/train.txt', 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "labels = []\n",
    "sentences = []\n",
    "sentence = ''\n",
    "for line in tqdm(lines):\n",
    "    if line != '\\n':\n",
    "        labels.append(line[2:].strip('\\n'))\n",
    "        sentence += line[0]\n",
    "    else:\n",
    "        sentences.append(sentence)\n",
    "        sentence = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['手机三脚架网红直播支架桌面自拍杆蓝牙遥控三脚架摄影拍摄拍照抖音看电视神器三角架便携伸缩懒人户外支撑架 【女神粉】自带三脚架+蓝牙遥控',\n",
       " '牛皮纸袋手提袋定制logo烘焙购物服装包装外卖打包袋子礼品袋纸质 黑色 32*11*25 大横100个']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-40', 'I-40', 'B-4', 'I-4', 'I-4', 'B-14', 'I-14', 'B-5', 'I-5', 'B-4']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'O': 319216, 'I-4': 312904, 'B-4': 167271, 'I-18': 141135, 'I-38': 131220, 'I-13': 94326, 'I-11': 92169, 'B-13': 64702, 'B-11': 60291, 'I-1': 58724, 'B-18': 54487, 'I-40': 52582, 'I-5': 51638, 'I-3': 41671, 'B-5': 40536, 'B-40': 32470, 'B-38': 30750, 'I-7': 30136, 'I-16': 28837, 'I-14': 25899, 'I-39': 25345, 'B-1': 25043, 'B-7': 24890, 'I-8': 23670, 'I-37': 23173, 'B-16': 22924, 'B-14': 22363, 'I-54': 20496, 'I-10': 19856, 'I-9': 19259, 'B-8': 18280, 'I-12': 17183, 'B-37': 15134, 'I-22': 14004, 'B-9': 12917, 'B-12': 12218, 'I-2': 11434, 'B-22': 9331, 'B-3': 9097, 'B-10': 8209, 'I-36': 8058, 'I-29': 6880, 'B-54': 6001, 'B-39': 4968, 'B-29': 4333, 'B-36': 3627, 'B-2': 3037, 'I-21': 2788, 'I-6': 2765, 'I-49': 2107, 'I-47': 1893, 'B-6': 1511, 'I-20': 1477, 'B-49': 1384, 'B-47': 1343, 'I-31': 1107, 'I-15': 957, 'B-31': 850, 'B-15': 810, 'I-30': 736, 'I-50': 664, 'I-41': 607, 'B-21': 605, 'B-20': 571, 'B-30': 540, 'B-41': 495, 'B-50': 389, 'I-34': 267, 'B-34': 260, 'I-19': 206, 'I-48': 201, 'I-52': 196, 'B-52': 174, 'B-48': 167, 'B-19': 132, 'I-43': 121, 'B-43': 88, 'I-28': 74, 'I-32': 53, 'I-46': 51, 'I-44': 48, 'B-32': 47, 'I-17': 42, 'B-44': 36, 'B-28': 34, 'I-23': 31, 'I-25': 31, 'B-17': 31, 'B-25': 29, 'B-46': 26, 'B-23': 22, 'I-42': 20, 'I-33': 19, 'B-51': 16, 'I-51': 16, 'B-33': 14, 'B-42': 11, 'I-24': 11, 'I-53': 6, 'B-24': 5, 'B-53': 5, 'B-35': 3, 'I-35': 2, 'B-26': 1, 'I-26': 1})\n"
     ]
    }
   ],
   "source": [
    "print(Counter(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/train_data/train.txt', 'r', encoding='utf-8') as f:\n",
    "    lines1 = f.readlines()\n",
    "with open('./submit/label.txt', 'r', encoding='utf-8') as f:\n",
    "    lines2 = f.readlines()\n",
    "with open('./submit/label_extend.txt', 'r', encoding='utf-8') as f:\n",
    "    lines3 = f.readlines()\n",
    "with open('./mix_train_data.txt', 'w', encoding='utf-8') as f:\n",
    "    for line in lines1:\n",
    "        f.write(line)\n",
    "    for line in lines2:\n",
    "        f.write(line)\n",
    "    for line in lines3:\n",
    "        f.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/train_data/unlabeled_train_data.txt', 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "import random\n",
    "random.shuffle(lines)\n",
    "with open('./sample_per_line_extend_data.txt', 'w', encoding='utf-8') as f:\n",
    "    for line in lines[:420000]:\n",
    "        f.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['【现货直发】A5简约线圈本笔记本子可爱韩版学生小清新记事本创意ins日记本君诚 花遇系列 2本装-经济\\n',\n",
       " '电动幕100吋16:9嵌入式隐藏天花电动幕布投影仪幕布抗光幕金属电动幕高清3D电动幕4K电 92吋微晶抗光 其它材质\\n',\n",
       " '安居星集成灶 智能厨卫厨房电器 AJX-S600-10蒸烤 黑色 天然气\\n',\n",
       " '矜遇 小粉兔可爱毛绒适用iPhonex苹果11手机壳8plus秋冬xsmax华为nova7【11月1 毛绒刺绣- 华为nova7pro\\n',\n",
       " '雅好 神器宝贝苹果13手机壳iPhone12ProMax来电发光11网红XS皮卡丘XR卡通动漫8P新 【神奇宝贝】七彩声控款 苹果11Pro(5.8寸)\\n',\n",
       " '华为MatePadPro妙控蓝牙键盘保护套带笔槽m6触控板10.8英吋平板pro电脑荣耀V6磁吸10 【七彩背光款】雅致黑+（滴水键帽）黑色触控键盘【送 【2021款】华为MatePad Pro -1\\n',\n",
       " '2020新款10.2软壳保护套Air1苹果9.7平板ipad234全包MINI45壳 紫色美少女 201910.2\\n',\n",
       " '独刺 闪粉6s星空苹果7plus手机壳8X星座滴胶r9r11p保护x7透明x9s/m68t8 透明款 VIVO X7\\n',\n",
       " '折纸正方形彩纸手工纸红色黄蓝紫绿黑白粉红手工专用纸千纸鹤剪纸 浅蓝 15厘米200张\\n',\n",
       " '畅尼 数据线闪充安卓充电线快充 适用于 白色 vivox5 x5pro x5prov X5max\\n']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['bert.embeddings.word_embeddings.weight', 'bert.embeddings.token_type_embeddings.weight', 'bert.embeddings.LayerNorm.weight', 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.self.query.weight', 'bert.encoder.layer.0.attention.self.query.bias', 'bert.encoder.layer.0.attention.self.key.weight', 'bert.encoder.layer.0.attention.self.key.bias', 'bert.encoder.layer.0.attention.self.value.weight', 'bert.encoder.layer.0.attention.self.value.bias', 'bert.encoder.layer.0.attention.output.dense.weight', 'bert.encoder.layer.0.attention.output.dense.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.bias', 'bert.encoder.layer.0.intermediate.dense.weight', 'bert.encoder.layer.0.intermediate.dense.bias', 'bert.encoder.layer.0.output.dense.weight', 'bert.encoder.layer.0.output.dense.bias', 'bert.encoder.layer.0.output.LayerNorm.weight', 'bert.encoder.layer.0.output.LayerNorm.bias', 'bert.encoder.layer.1.attention.self.query.weight', 'bert.encoder.layer.1.attention.self.query.bias', 'bert.encoder.layer.1.attention.self.key.weight', 'bert.encoder.layer.1.attention.self.key.bias', 'bert.encoder.layer.1.attention.self.value.weight', 'bert.encoder.layer.1.attention.self.value.bias', 'bert.encoder.layer.1.attention.output.dense.weight', 'bert.encoder.layer.1.attention.output.dense.bias', 'bert.encoder.layer.1.attention.output.LayerNorm.weight', 'bert.encoder.layer.1.attention.output.LayerNorm.bias', 'bert.encoder.layer.1.intermediate.dense.weight', 'bert.encoder.layer.1.intermediate.dense.bias', 'bert.encoder.layer.1.output.dense.weight', 'bert.encoder.layer.1.output.dense.bias', 'bert.encoder.layer.1.output.LayerNorm.weight', 'bert.encoder.layer.1.output.LayerNorm.bias', 'bert.encoder.layer.2.attention.self.query.weight', 'bert.encoder.layer.2.attention.self.query.bias', 'bert.encoder.layer.2.attention.self.key.weight', 'bert.encoder.layer.2.attention.self.key.bias', 'bert.encoder.layer.2.attention.self.value.weight', 'bert.encoder.layer.2.attention.self.value.bias', 'bert.encoder.layer.2.attention.output.dense.weight', 'bert.encoder.layer.2.attention.output.dense.bias', 'bert.encoder.layer.2.attention.output.LayerNorm.weight', 'bert.encoder.layer.2.attention.output.LayerNorm.bias', 'bert.encoder.layer.2.intermediate.dense.weight', 'bert.encoder.layer.2.intermediate.dense.bias', 'bert.encoder.layer.2.output.dense.weight', 'bert.encoder.layer.2.output.dense.bias', 'bert.encoder.layer.2.output.LayerNorm.weight', 'bert.encoder.layer.2.output.LayerNorm.bias', 'bert.encoder.layer.3.attention.self.query.weight', 'bert.encoder.layer.3.attention.self.query.bias', 'bert.encoder.layer.3.attention.self.key.weight', 'bert.encoder.layer.3.attention.self.key.bias', 'bert.encoder.layer.3.attention.self.value.weight', 'bert.encoder.layer.3.attention.self.value.bias', 'bert.encoder.layer.3.attention.output.dense.weight', 'bert.encoder.layer.3.attention.output.dense.bias', 'bert.encoder.layer.3.attention.output.LayerNorm.weight', 'bert.encoder.layer.3.attention.output.LayerNorm.bias', 'bert.encoder.layer.3.intermediate.dense.weight', 'bert.encoder.layer.3.intermediate.dense.bias', 'bert.encoder.layer.3.output.dense.weight', 'bert.encoder.layer.3.output.dense.bias', 'bert.encoder.layer.3.output.LayerNorm.weight', 'bert.encoder.layer.3.output.LayerNorm.bias', 'bert.encoder.layer.4.attention.self.query.weight', 'bert.encoder.layer.4.attention.self.query.bias', 'bert.encoder.layer.4.attention.self.key.weight', 'bert.encoder.layer.4.attention.self.key.bias', 'bert.encoder.layer.4.attention.self.value.weight', 'bert.encoder.layer.4.attention.self.value.bias', 'bert.encoder.layer.4.attention.output.dense.weight', 'bert.encoder.layer.4.attention.output.dense.bias', 'bert.encoder.layer.4.attention.output.LayerNorm.weight', 'bert.encoder.layer.4.attention.output.LayerNorm.bias', 'bert.encoder.layer.4.intermediate.dense.weight', 'bert.encoder.layer.4.intermediate.dense.bias', 'bert.encoder.layer.4.output.dense.weight', 'bert.encoder.layer.4.output.dense.bias', 'bert.encoder.layer.4.output.LayerNorm.weight', 'bert.encoder.layer.4.output.LayerNorm.bias', 'bert.encoder.layer.5.attention.self.query.weight', 'bert.encoder.layer.5.attention.self.query.bias', 'bert.encoder.layer.5.attention.self.key.weight', 'bert.encoder.layer.5.attention.self.key.bias', 'bert.encoder.layer.5.attention.self.value.weight', 'bert.encoder.layer.5.attention.self.value.bias', 'bert.encoder.layer.5.attention.output.dense.weight', 'bert.encoder.layer.5.attention.output.dense.bias', 'bert.encoder.layer.5.attention.output.LayerNorm.weight', 'bert.encoder.layer.5.attention.output.LayerNorm.bias', 'bert.encoder.layer.5.intermediate.dense.weight', 'bert.encoder.layer.5.intermediate.dense.bias', 'bert.encoder.layer.5.output.dense.weight', 'bert.encoder.layer.5.output.dense.bias', 'bert.encoder.layer.5.output.LayerNorm.weight', 'bert.encoder.layer.5.output.LayerNorm.bias', 'bert.encoder.layer.6.attention.self.query.weight', 'bert.encoder.layer.6.attention.self.query.bias', 'bert.encoder.layer.6.attention.self.key.weight', 'bert.encoder.layer.6.attention.self.key.bias', 'bert.encoder.layer.6.attention.self.value.weight', 'bert.encoder.layer.6.attention.self.value.bias', 'bert.encoder.layer.6.attention.output.dense.weight', 'bert.encoder.layer.6.attention.output.dense.bias', 'bert.encoder.layer.6.attention.output.LayerNorm.weight', 'bert.encoder.layer.6.attention.output.LayerNorm.bias', 'bert.encoder.layer.6.intermediate.dense.weight', 'bert.encoder.layer.6.intermediate.dense.bias', 'bert.encoder.layer.6.output.dense.weight', 'bert.encoder.layer.6.output.dense.bias', 'bert.encoder.layer.6.output.LayerNorm.weight', 'bert.encoder.layer.6.output.LayerNorm.bias', 'bert.encoder.layer.7.attention.self.query.weight', 'bert.encoder.layer.7.attention.self.query.bias', 'bert.encoder.layer.7.attention.self.key.weight', 'bert.encoder.layer.7.attention.self.key.bias', 'bert.encoder.layer.7.attention.self.value.weight', 'bert.encoder.layer.7.attention.self.value.bias', 'bert.encoder.layer.7.attention.output.dense.weight', 'bert.encoder.layer.7.attention.output.dense.bias', 'bert.encoder.layer.7.attention.output.LayerNorm.weight', 'bert.encoder.layer.7.attention.output.LayerNorm.bias', 'bert.encoder.layer.7.intermediate.dense.weight', 'bert.encoder.layer.7.intermediate.dense.bias', 'bert.encoder.layer.7.output.dense.weight', 'bert.encoder.layer.7.output.dense.bias', 'bert.encoder.layer.7.output.LayerNorm.weight', 'bert.encoder.layer.7.output.LayerNorm.bias', 'bert.encoder.layer.8.attention.self.query.weight', 'bert.encoder.layer.8.attention.self.query.bias', 'bert.encoder.layer.8.attention.self.key.weight', 'bert.encoder.layer.8.attention.self.key.bias', 'bert.encoder.layer.8.attention.self.value.weight', 'bert.encoder.layer.8.attention.self.value.bias', 'bert.encoder.layer.8.attention.output.dense.weight', 'bert.encoder.layer.8.attention.output.dense.bias', 'bert.encoder.layer.8.attention.output.LayerNorm.weight', 'bert.encoder.layer.8.attention.output.LayerNorm.bias', 'bert.encoder.layer.8.intermediate.dense.weight', 'bert.encoder.layer.8.intermediate.dense.bias', 'bert.encoder.layer.8.output.dense.weight', 'bert.encoder.layer.8.output.dense.bias', 'bert.encoder.layer.8.output.LayerNorm.weight', 'bert.encoder.layer.8.output.LayerNorm.bias', 'bert.encoder.layer.9.attention.self.query.weight', 'bert.encoder.layer.9.attention.self.query.bias', 'bert.encoder.layer.9.attention.self.key.weight', 'bert.encoder.layer.9.attention.self.key.bias', 'bert.encoder.layer.9.attention.self.value.weight', 'bert.encoder.layer.9.attention.self.value.bias', 'bert.encoder.layer.9.attention.output.dense.weight', 'bert.encoder.layer.9.attention.output.dense.bias', 'bert.encoder.layer.9.attention.output.LayerNorm.weight', 'bert.encoder.layer.9.attention.output.LayerNorm.bias', 'bert.encoder.layer.9.intermediate.dense.weight', 'bert.encoder.layer.9.intermediate.dense.bias', 'bert.encoder.layer.9.output.dense.weight', 'bert.encoder.layer.9.output.dense.bias', 'bert.encoder.layer.9.output.LayerNorm.weight', 'bert.encoder.layer.9.output.LayerNorm.bias', 'bert.encoder.layer.10.attention.self.query.weight', 'bert.encoder.layer.10.attention.self.query.bias', 'bert.encoder.layer.10.attention.self.key.weight', 'bert.encoder.layer.10.attention.self.key.bias', 'bert.encoder.layer.10.attention.self.value.weight', 'bert.encoder.layer.10.attention.self.value.bias', 'bert.encoder.layer.10.attention.output.dense.weight', 'bert.encoder.layer.10.attention.output.dense.bias', 'bert.encoder.layer.10.attention.output.LayerNorm.weight', 'bert.encoder.layer.10.attention.output.LayerNorm.bias', 'bert.encoder.layer.10.intermediate.dense.weight', 'bert.encoder.layer.10.intermediate.dense.bias', 'bert.encoder.layer.10.output.dense.weight', 'bert.encoder.layer.10.output.dense.bias', 'bert.encoder.layer.10.output.LayerNorm.weight', 'bert.encoder.layer.10.output.LayerNorm.bias', 'bert.encoder.layer.11.attention.self.query.weight', 'bert.encoder.layer.11.attention.self.query.bias', 'bert.encoder.layer.11.attention.self.key.weight', 'bert.encoder.layer.11.attention.self.key.bias', 'bert.encoder.layer.11.attention.self.value.weight', 'bert.encoder.layer.11.attention.self.value.bias', 'bert.encoder.layer.11.attention.output.dense.weight', 'bert.encoder.layer.11.attention.output.dense.bias', 'bert.encoder.layer.11.attention.output.LayerNorm.weight', 'bert.encoder.layer.11.attention.output.LayerNorm.bias', 'bert.encoder.layer.11.intermediate.dense.weight', 'bert.encoder.layer.11.intermediate.dense.bias', 'bert.encoder.layer.11.output.dense.weight', 'bert.encoder.layer.11.output.dense.bias', 'bert.encoder.layer.11.output.LayerNorm.weight', 'bert.encoder.layer.11.output.LayerNorm.bias', 'bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.load('../pretrain_model/nezha-base/pytorch_model.bin').keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings.word_embeddings.weight\n",
      "embeddings.token_type_embeddings.weight\n",
      "embeddings.LayerNorm.weight\n",
      "embeddings.LayerNorm.bias\n",
      "encoder.layer.0.attention.self.query.weight\n",
      "encoder.layer.0.attention.self.query.bias\n",
      "encoder.layer.0.attention.self.key.weight\n",
      "encoder.layer.0.attention.self.key.bias\n",
      "encoder.layer.0.attention.self.value.weight\n",
      "encoder.layer.0.attention.self.value.bias\n",
      "encoder.layer.0.attention.output.dense.weight\n",
      "encoder.layer.0.attention.output.dense.bias\n",
      "encoder.layer.0.attention.output.LayerNorm.weight\n",
      "encoder.layer.0.attention.output.LayerNorm.bias\n",
      "encoder.layer.0.intermediate.dense.weight\n",
      "encoder.layer.0.intermediate.dense.bias\n",
      "encoder.layer.0.output.dense.weight\n",
      "encoder.layer.0.output.dense.bias\n",
      "encoder.layer.0.output.LayerNorm.weight\n",
      "encoder.layer.0.output.LayerNorm.bias\n",
      "encoder.layer.1.attention.self.query.weight\n",
      "encoder.layer.1.attention.self.query.bias\n",
      "encoder.layer.1.attention.self.key.weight\n",
      "encoder.layer.1.attention.self.key.bias\n",
      "encoder.layer.1.attention.self.value.weight\n",
      "encoder.layer.1.attention.self.value.bias\n",
      "encoder.layer.1.attention.output.dense.weight\n",
      "encoder.layer.1.attention.output.dense.bias\n",
      "encoder.layer.1.attention.output.LayerNorm.weight\n",
      "encoder.layer.1.attention.output.LayerNorm.bias\n",
      "encoder.layer.1.intermediate.dense.weight\n",
      "encoder.layer.1.intermediate.dense.bias\n",
      "encoder.layer.1.output.dense.weight\n",
      "encoder.layer.1.output.dense.bias\n",
      "encoder.layer.1.output.LayerNorm.weight\n",
      "encoder.layer.1.output.LayerNorm.bias\n",
      "encoder.layer.2.attention.self.query.weight\n",
      "encoder.layer.2.attention.self.query.bias\n",
      "encoder.layer.2.attention.self.key.weight\n",
      "encoder.layer.2.attention.self.key.bias\n",
      "encoder.layer.2.attention.self.value.weight\n",
      "encoder.layer.2.attention.self.value.bias\n",
      "encoder.layer.2.attention.output.dense.weight\n",
      "encoder.layer.2.attention.output.dense.bias\n",
      "encoder.layer.2.attention.output.LayerNorm.weight\n",
      "encoder.layer.2.attention.output.LayerNorm.bias\n",
      "encoder.layer.2.intermediate.dense.weight\n",
      "encoder.layer.2.intermediate.dense.bias\n",
      "encoder.layer.2.output.dense.weight\n",
      "encoder.layer.2.output.dense.bias\n",
      "encoder.layer.2.output.LayerNorm.weight\n",
      "encoder.layer.2.output.LayerNorm.bias\n",
      "encoder.layer.3.attention.self.query.weight\n",
      "encoder.layer.3.attention.self.query.bias\n",
      "encoder.layer.3.attention.self.key.weight\n",
      "encoder.layer.3.attention.self.key.bias\n",
      "encoder.layer.3.attention.self.value.weight\n",
      "encoder.layer.3.attention.self.value.bias\n",
      "encoder.layer.3.attention.output.dense.weight\n",
      "encoder.layer.3.attention.output.dense.bias\n",
      "encoder.layer.3.attention.output.LayerNorm.weight\n",
      "encoder.layer.3.attention.output.LayerNorm.bias\n",
      "encoder.layer.3.intermediate.dense.weight\n",
      "encoder.layer.3.intermediate.dense.bias\n",
      "encoder.layer.3.output.dense.weight\n",
      "encoder.layer.3.output.dense.bias\n",
      "encoder.layer.3.output.LayerNorm.weight\n",
      "encoder.layer.3.output.LayerNorm.bias\n",
      "encoder.layer.4.attention.self.query.weight\n",
      "encoder.layer.4.attention.self.query.bias\n",
      "encoder.layer.4.attention.self.key.weight\n",
      "encoder.layer.4.attention.self.key.bias\n",
      "encoder.layer.4.attention.self.value.weight\n",
      "encoder.layer.4.attention.self.value.bias\n",
      "encoder.layer.4.attention.output.dense.weight\n",
      "encoder.layer.4.attention.output.dense.bias\n",
      "encoder.layer.4.attention.output.LayerNorm.weight\n",
      "encoder.layer.4.attention.output.LayerNorm.bias\n",
      "encoder.layer.4.intermediate.dense.weight\n",
      "encoder.layer.4.intermediate.dense.bias\n",
      "encoder.layer.4.output.dense.weight\n",
      "encoder.layer.4.output.dense.bias\n",
      "encoder.layer.4.output.LayerNorm.weight\n",
      "encoder.layer.4.output.LayerNorm.bias\n",
      "encoder.layer.5.attention.self.query.weight\n",
      "encoder.layer.5.attention.self.query.bias\n",
      "encoder.layer.5.attention.self.key.weight\n",
      "encoder.layer.5.attention.self.key.bias\n",
      "encoder.layer.5.attention.self.value.weight\n",
      "encoder.layer.5.attention.self.value.bias\n",
      "encoder.layer.5.attention.output.dense.weight\n",
      "encoder.layer.5.attention.output.dense.bias\n",
      "encoder.layer.5.attention.output.LayerNorm.weight\n",
      "encoder.layer.5.attention.output.LayerNorm.bias\n",
      "encoder.layer.5.intermediate.dense.weight\n",
      "encoder.layer.5.intermediate.dense.bias\n",
      "encoder.layer.5.output.dense.weight\n",
      "encoder.layer.5.output.dense.bias\n",
      "encoder.layer.5.output.LayerNorm.weight\n",
      "encoder.layer.5.output.LayerNorm.bias\n",
      "encoder.layer.6.attention.self.query.weight\n",
      "encoder.layer.6.attention.self.query.bias\n",
      "encoder.layer.6.attention.self.key.weight\n",
      "encoder.layer.6.attention.self.key.bias\n",
      "encoder.layer.6.attention.self.value.weight\n",
      "encoder.layer.6.attention.self.value.bias\n",
      "encoder.layer.6.attention.output.dense.weight\n",
      "encoder.layer.6.attention.output.dense.bias\n",
      "encoder.layer.6.attention.output.LayerNorm.weight\n",
      "encoder.layer.6.attention.output.LayerNorm.bias\n",
      "encoder.layer.6.intermediate.dense.weight\n",
      "encoder.layer.6.intermediate.dense.bias\n",
      "encoder.layer.6.output.dense.weight\n",
      "encoder.layer.6.output.dense.bias\n",
      "encoder.layer.6.output.LayerNorm.weight\n",
      "encoder.layer.6.output.LayerNorm.bias\n",
      "encoder.layer.7.attention.self.query.weight\n",
      "encoder.layer.7.attention.self.query.bias\n",
      "encoder.layer.7.attention.self.key.weight\n",
      "encoder.layer.7.attention.self.key.bias\n",
      "encoder.layer.7.attention.self.value.weight\n",
      "encoder.layer.7.attention.self.value.bias\n",
      "encoder.layer.7.attention.output.dense.weight\n",
      "encoder.layer.7.attention.output.dense.bias\n",
      "encoder.layer.7.attention.output.LayerNorm.weight\n",
      "encoder.layer.7.attention.output.LayerNorm.bias\n",
      "encoder.layer.7.intermediate.dense.weight\n",
      "encoder.layer.7.intermediate.dense.bias\n",
      "encoder.layer.7.output.dense.weight\n",
      "encoder.layer.7.output.dense.bias\n",
      "encoder.layer.7.output.LayerNorm.weight\n",
      "encoder.layer.7.output.LayerNorm.bias\n",
      "encoder.layer.8.attention.self.query.weight\n",
      "encoder.layer.8.attention.self.query.bias\n",
      "encoder.layer.8.attention.self.key.weight\n",
      "encoder.layer.8.attention.self.key.bias\n",
      "encoder.layer.8.attention.self.value.weight\n",
      "encoder.layer.8.attention.self.value.bias\n",
      "encoder.layer.8.attention.output.dense.weight\n",
      "encoder.layer.8.attention.output.dense.bias\n",
      "encoder.layer.8.attention.output.LayerNorm.weight\n",
      "encoder.layer.8.attention.output.LayerNorm.bias\n",
      "encoder.layer.8.intermediate.dense.weight\n",
      "encoder.layer.8.intermediate.dense.bias\n",
      "encoder.layer.8.output.dense.weight\n",
      "encoder.layer.8.output.dense.bias\n",
      "encoder.layer.8.output.LayerNorm.weight\n",
      "encoder.layer.8.output.LayerNorm.bias\n",
      "encoder.layer.9.attention.self.query.weight\n",
      "encoder.layer.9.attention.self.query.bias\n",
      "encoder.layer.9.attention.self.key.weight\n",
      "encoder.layer.9.attention.self.key.bias\n",
      "encoder.layer.9.attention.self.value.weight\n",
      "encoder.layer.9.attention.self.value.bias\n",
      "encoder.layer.9.attention.output.dense.weight\n",
      "encoder.layer.9.attention.output.dense.bias\n",
      "encoder.layer.9.attention.output.LayerNorm.weight\n",
      "encoder.layer.9.attention.output.LayerNorm.bias\n",
      "encoder.layer.9.intermediate.dense.weight\n",
      "encoder.layer.9.intermediate.dense.bias\n",
      "encoder.layer.9.output.dense.weight\n",
      "encoder.layer.9.output.dense.bias\n",
      "encoder.layer.9.output.LayerNorm.weight\n",
      "encoder.layer.9.output.LayerNorm.bias\n",
      "encoder.layer.10.attention.self.query.weight\n",
      "encoder.layer.10.attention.self.query.bias\n",
      "encoder.layer.10.attention.self.key.weight\n",
      "encoder.layer.10.attention.self.key.bias\n",
      "encoder.layer.10.attention.self.value.weight\n",
      "encoder.layer.10.attention.self.value.bias\n",
      "encoder.layer.10.attention.output.dense.weight\n",
      "encoder.layer.10.attention.output.dense.bias\n",
      "encoder.layer.10.attention.output.LayerNorm.weight\n",
      "encoder.layer.10.attention.output.LayerNorm.bias\n",
      "encoder.layer.10.intermediate.dense.weight\n",
      "encoder.layer.10.intermediate.dense.bias\n",
      "encoder.layer.10.output.dense.weight\n",
      "encoder.layer.10.output.dense.bias\n",
      "encoder.layer.10.output.LayerNorm.weight\n",
      "encoder.layer.10.output.LayerNorm.bias\n",
      "encoder.layer.11.attention.self.query.weight\n",
      "encoder.layer.11.attention.self.query.bias\n",
      "encoder.layer.11.attention.self.key.weight\n",
      "encoder.layer.11.attention.self.key.bias\n",
      "encoder.layer.11.attention.self.value.weight\n",
      "encoder.layer.11.attention.self.value.bias\n",
      "encoder.layer.11.attention.output.dense.weight\n",
      "encoder.layer.11.attention.output.dense.bias\n",
      "encoder.layer.11.attention.output.LayerNorm.weight\n",
      "encoder.layer.11.attention.output.LayerNorm.bias\n",
      "encoder.layer.11.intermediate.dense.weight\n",
      "encoder.layer.11.intermediate.dense.bias\n",
      "encoder.layer.11.output.dense.weight\n",
      "encoder.layer.11.output.dense.bias\n",
      "encoder.layer.11.output.LayerNorm.weight\n",
      "encoder.layer.11.output.LayerNorm.bias\n",
      "pooler.dense.weight\n",
      "pooler.dense.bias\n"
     ]
    }
   ],
   "source": [
    "from nezha.modeling_nezha import NeZhaModel\n",
    "from nezha.configuration_nezha import NeZhaConfig\n",
    "config = NeZhaConfig.from_pretrained('../pretrain_model/nezha-base/config.json')\n",
    "model = NeZhaModel(config)\n",
    "for n, p in model.named_parameters():\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import read_data\n",
    "import pandas as pd\n",
    "\n",
    "datalist, label_set = read_data('../data/train_500.txt')\n",
    "train_data_df = pd.DataFrame(datalist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>手机三脚架网红直播支架桌面自拍杆蓝牙遥控三脚架摄影拍摄拍照抖音看电视神器三角架便携伸缩懒人户...</td>\n",
       "      <td>[{'start_idx': 0, 'end_idx': 1, 'type': '40', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>牛皮纸袋手提袋定制logo烘焙购物服装包装外卖打包袋子礼品袋纸质 黑色 32*11*25 大...</td>\n",
       "      <td>[{'start_idx': 0, 'end_idx': 3, 'type': '4', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>彩色金属镂空鱼尾夹长尾夹 手帐设计绘图文具收纳 夹子 鱼尾夹炫彩大号</td>\n",
       "      <td>[{'start_idx': 0, 'end_idx': 1, 'type': '16', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bose SoundSport Free 真无线蓝牙耳机 运动耳机 博士防掉落耳塞 黑色</td>\n",
       "      <td>[{'start_idx': 0, 'end_idx': 3, 'type': '1', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>壁挂炉专用水空调散热器带风扇暖气片水暖空调明装吹风机盘管家用 流线85#6进6出24铜管(左...</td>\n",
       "      <td>[{'start_idx': 0, 'end_idx': 2, 'type': '4', '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text                                              label\n",
       "0  手机三脚架网红直播支架桌面自拍杆蓝牙遥控三脚架摄影拍摄拍照抖音看电视神器三角架便携伸缩懒人户...  [{'start_idx': 0, 'end_idx': 1, 'type': '40', ...\n",
       "1  牛皮纸袋手提袋定制logo烘焙购物服装包装外卖打包袋子礼品袋纸质 黑色 32*11*25 大...  [{'start_idx': 0, 'end_idx': 3, 'type': '4', '...\n",
       "2                 彩色金属镂空鱼尾夹长尾夹 手帐设计绘图文具收纳 夹子 鱼尾夹炫彩大号  [{'start_idx': 0, 'end_idx': 1, 'type': '16', ...\n",
       "3       Bose SoundSport Free 真无线蓝牙耳机 运动耳机 博士防掉落耳塞 黑色  [{'start_idx': 0, 'end_idx': 3, 'type': '1', '...\n",
       "4  壁挂炉专用水空调散热器带风扇暖气片水暖空调明装吹风机盘管家用 流线85#6进6出24铜管(左...  [{'start_idx': 0, 'end_idx': 2, 'type': '4', '..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " '10',\n",
       " '11',\n",
       " '12',\n",
       " '13',\n",
       " '14',\n",
       " '15',\n",
       " '16',\n",
       " '18',\n",
       " '19',\n",
       " '2',\n",
       " '20',\n",
       " '21',\n",
       " '22',\n",
       " '23',\n",
       " '29',\n",
       " '3',\n",
       " '30',\n",
       " '31',\n",
       " '34',\n",
       " '36',\n",
       " '37',\n",
       " '38',\n",
       " '39',\n",
       " '4',\n",
       " '40',\n",
       " '41',\n",
       " '43',\n",
       " '46',\n",
       " '47',\n",
       " '48',\n",
       " '49',\n",
       " '5',\n",
       " '50',\n",
       " '52',\n",
       " '54',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " 'O']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000000 200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('./lebert/w2v/w2v_model/tencent-ailab-embedding-zh-d200-v0.2.0-s.txt', 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from ark_nlp.model.ner.global_pointer_bert import get_default_model_optimizer\n",
    "from nezha.configuration_nezha import NeZhaConfig\n",
    "from predictor import GlobalPointerNERLEPredictor\n",
    "from model import GlobalPointerLEModel\n",
    "from lebert.model.lebert import LENeZha\n",
    "from data import GPLENERDataset\n",
    "from tokenizer import BertTokenizer\n",
    "from utils import WarmupLinearSchedule, seed_everything\n",
    "from sklearn.model_selection import train_test_split\n",
    "from task import MyGlobalPointerNERTask\n",
    "from data import read_data, read_test_data, build_lebert_files\n",
    "from tqdm import tqdm\n",
    "from argparse import ArgumentParser\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(args):\n",
    "    datalist, label_set = read_data(args.data_path)\n",
    "    train_data_df = pd.DataFrame(datalist)\n",
    "    train_data_df['label'] = train_data_df['label'].apply(lambda x: str(x))\n",
    "    train_data_df, _ = train_test_split(\n",
    "        train_data_df, test_size=0.1, shuffle=True, random_state=args.seed)\n",
    "\n",
    "    lexicon_tree, pretrained_word_embedding, word_vocab = build_lebert_files(\n",
    "        args)\n",
    "\n",
    "    ner_train_dataset = GPLENERDataset(\n",
    "        train_data_df, lexicon_tree, word_vocab, categories=label_set)\n",
    "\n",
    "    tokenizer = BertTokenizer(vocab=args.model_name_or_path,\n",
    "                              max_seq_len=args.max_seq_len)\n",
    "    config = NeZhaConfig.from_pretrained(args.model_name_or_path,\n",
    "                                         num_labels=len(ner_train_dataset.cat2id))\n",
    "    encoder = LENeZha(config, pretrained_word_embedding)\n",
    "    model = GlobalPointerLEModel(config, encoder)\n",
    "    model.load_state_dict(torch.load(args.predict_model))\n",
    "    model.to(torch.device(f'cuda:{args.cuda_device}'))\n",
    "\n",
    "    ner_predictor_instance = GlobalPointerNERLEPredictor(\n",
    "        model, tokenizer, lexicon_tree, word_vocab, ner_train_dataset.cat2id)\n",
    "\n",
    "    predict_results = []\n",
    "\n",
    "    with open(args.test_file, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "        for _line in tqdm(lines):\n",
    "            label = len(_line) * ['O']\n",
    "            for _preditc in ner_predictor_instance.predict_one_sample(_line[:-1]):\n",
    "                if 'I' in label[_preditc['start_idx']]:\n",
    "                    continue\n",
    "                if 'B' in label[_preditc['start_idx']] and 'O' not in label[_preditc['end_idx']]:\n",
    "                    continue\n",
    "                if 'O' in label[_preditc['start_idx']] and 'B' in label[_preditc['end_idx']]:\n",
    "                    continue\n",
    "\n",
    "                label[_preditc['start_idx']] = 'B-' + _preditc['type']\n",
    "                label[_preditc['start_idx']+1: _preditc['end_idx']+1] = (\n",
    "                    _preditc['end_idx'] - _preditc['start_idx']) * [('I-' + _preditc['type'])]\n",
    "\n",
    "            predict_results.append([_line, label])\n",
    "\n",
    "    os.makedirs(args.save_path, exist_ok=True)\n",
    "    with open(os.path.join(args.save_path, f'{args.model_type}.txt'), 'w', encoding='utf-8') as f:\n",
    "        for _result in predict_results:\n",
    "            for word, tag in zip(_result[0], _result[1]):\n",
    "                if word == '\\n':\n",
    "                    continue\n",
    "                f.write(f'{word} {tag}\\n')\n",
    "            f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2335"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(1.23353463456, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logs:\n",
    "    def __init__(self, path) -> None:\n",
    "        self.path = path\n",
    "        with open(self.path, 'w', encoding='utf-8') as f:\n",
    "            f.write('')\n",
    "\n",
    "    def write(self, content):\n",
    "        with open(self.path, 'a', encoding='utf-8') as f:\n",
    "            f.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cv(args):\n",
    "    datalist, label_set = read_data(args.data_path)\n",
    "    data_df = pd.DataFrame(datalist)\n",
    "    data_df['label'] = data_df['label'].apply(lambda x: str(x))\n",
    "\n",
    "    kfold = KFold(n_splits=10, shuffle=True, random_state=args.seed)\n",
    "\n",
    "    for fold, (train_idx, dev_idx) in enumerate(kfold.split(data_df)):\n",
    "        print(f'========== {fold + 1} ==========')\n",
    "        args.checkpoint = os.path.join(args.checkpoint, args.model_type)\n",
    "        args.model_type = f'{args.model_type}_{fold + 1}'\n",
    "        train_data_df, dev_data_df = data_df.iloc[train_idx], data_df.iloc[dev_idx]\n",
    "        ner_train_dataset = Dataset(train_data_df, categories=label_set)\n",
    "        ner_dev_dataset = Dataset(\n",
    "            dev_data_df, categories=ner_train_dataset.categories)\n",
    "\n",
    "        tokenizer = BertTokenizer(vocab=args.model_name_or_path,\n",
    "                                  max_seq_len=args.max_seq_len)\n",
    "        config = NeZhaConfig.from_pretrained(args.model_name_or_path,\n",
    "                                             num_labels=len(ner_train_dataset.cat2id))\n",
    "        encoder = NeZhaModel.from_pretrained(args.model_name_or_path,\n",
    "                                             config=config)\n",
    "        dl_module = GlobalPointerModel(config, encoder)\n",
    "\n",
    "        ner_train_dataset.convert_to_ids(tokenizer)\n",
    "        ner_dev_dataset.convert_to_ids(tokenizer)\n",
    "\n",
    "        train_steps = args.num_epochs * \\\n",
    "            int(math.ceil(len(ner_train_dataset) / args.batch_size))\n",
    "        optimizer = get_default_model_optimizer(dl_module)\n",
    "        scheduler = WarmupLinearSchedule(\n",
    "            optimizer, warmup_steps=train_steps * args.warmup_ratio, t_total=train_steps)\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        model = MyGlobalPointerNERTask(\n",
    "            dl_module, optimizer, 'gpce',\n",
    "            scheduler=scheduler,\n",
    "            ema_decay=args.ema_decay,\n",
    "            cuda_device=args.cuda_device)\n",
    "\n",
    "        model.fit(args,\n",
    "                  ner_train_dataset,\n",
    "                  ner_dev_dataset,\n",
    "                  lr=args.learning_rate,\n",
    "                  epochs=args.num_epochs,\n",
    "                  batch_size=args.batch_size,\n",
    "                  gradient_accumulation_steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 2, 2), (2, 3, 3), (3, 5, 5), (4, 6, 7)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = [[1, 2, 3, 4], [2, 3, 5, 6], [2, 3, 5, 7]]\n",
    "list(zip(*l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 2) [(2, 2)]\n",
      "(2, 3, 3) [(3, 2)]\n",
      "(3, 5, 5) [(5, 2)]\n",
      "(4, 6, 7) [(4, 1)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "l = [[1, 2, 3, 4], [2, 3, 5, 6], [2, 3, 5, 7]]\n",
    "list(zip(*l))\n",
    "for row in zip(*l):\n",
    "    print(row, Counter(row).most_common(n=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3b80add2a2b11d514977d8a594b381c4c27ef80fe29cc35ee1dc587a338e4233"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
